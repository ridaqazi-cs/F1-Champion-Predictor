# F1 Pitstop Champion Prediction

This repository contains a Python pipeline to predict Formula 1 season champions using pitstop and race data from 2018 to 2024. It covers data preprocessing, feature engineering, exploratory visualization, model training, and evaluation.

---

## Project Overview

Predict which driver will become the Formula 1 World Champion next season by leveraging pitstop performance, weather, and race metrics. We train four classifiers:

* Logistic Regression
* Random Forest
* Naive Bayes
* K-Nearest Neighbors (KNN)

and compare their accuracies and F1 scores.

---

## Pipeline Steps

### 1. Load & Encode Drivers

* Read the CSV into a pandas DataFrame.
* Convert driver names to numeric codes using `pd.factorize` (or `LabelEncoder`).

### 2. Compute Season Points & Champions

* Map finishing positions to FIA points (25 for 1st, 18 for 2nd, etc.).
* Sum points per driver per season.
* Flag the driver with the highest points as the season champion (`IsChampion`).

### 3. Clean & Drop Columns

* Remove unnecessary text columns (race name, date, location, etc.).
* Retain only numeric and categorical features relevant for modeling.

### 4. Handle Missing Values

* **Numeric**: Fill missing values with column medians.
* **Categorical**: Fill missing values with the mode (most frequent value).

### 5. Aggregate Features

* Group data by `Season` and `DriverCode` to create a single row per driver-season.
* Compute statistics:

  * **Numeric**: Mean or sum for metrics like pit stops, lap variation, total laps.
  * **Mode**: Most common values for `Constructor` and `Tire Compound`.
  * **Label**: Maximum of `IsChampion` to indicate if the driver won that season.

### 6. Exploratory Visualizations

* **Correlation Matrix**: Visualize inter-feature correlations.
* **Feature Importances**: Display top 10 features from a quick Random Forest.

### 7. Feature Selection & Importances

* Apply `SelectKBest` (ANOVA F-test) to score all features.
* Plot the highest-scoring features.

### 8. Prepare the ML Dataset

* Create the `ChampionNext` label by shifting `IsChampion` to the next season.
* Split into **training** (seasons ≤2022) and **testing** (season = 2023).
* Drop identifier columns (`Season`, `DriverCode`) before modeling.

### 9. Model Training & Evaluation

* Balance the training set using `RandomOverSampler` to handle class imbalance.
* Train the following models:

  * Logistic Regression (`class_weight='balanced'`)
  * Random Forest (`max_depth=5`)
  * Gaussian Naive Bayes
  * KNN (`n_neighbors=5`)
* Evaluate on the 2023 test set:

  * Accuracy
  * Weighted F1 score
  * Classification report
  * Confusion matrix

| Model               | Accuracy | F1 Score |
| ------------------- | -------- | -------- |
| Logistic Regression | 0.XXX    | 0.XXX    |
| Random Forest       | 0.XXX    | 0.XXX    |
| Naive Bayes         | 0.XXX    | 0.XXX    |
| KNN                 | 0.XXX    | 0.XXX    |

---

### 10. Final Model & 2025 Prediction

* Retrain the best-performing model on all data up to 2023.
* Predict championship probabilities for each driver in the 2024 season.
* Output the top-5 drivers by predicted probability.

---

## License

This project is licensed under the MIT License © 2025
