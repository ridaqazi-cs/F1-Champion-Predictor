# F1 Pitstop Champion Prediction

This repository contains a Python pipeline to predict Formula 1 season champions using pitstop and race data from 2018 to 2024. It covers data preprocessing, feature engineering, exploratory visualization, model training, and evaluation.

## Project Overview

Predict which driver will become the Formula 1 World Champion next season by leveraging pitstop performance, weather, and race metrics. We train four classifiers:

* Logistic Regression
* Random Forest
* Naive Bayes
* K-Nearest Neighbors (KNN)

and compare their performance.

## Pipeline Steps

1. **Load & Encode Drivers**

   * Read the CSV into a pandas DataFrame.
   * Convert driver names to numeric codes using `pd.factorize`.

2. **Compute Season Points & Champions**

   * Map finishing positions to FIA points (25 for 1st, 18 for 2nd, etc.).
   * Sum points per driver per season.
   * Flag the driver with the highest points as champion (`IsChampion`).

3. **Clean & Drop Columns**

   * Remove unneeded text columns (race name, date, location, etc.).
   * Keep only numeric and categorical features for modeling.

4. **Handle Missing Values**

   * **Numeric**: Fill missing with column medians.
   * **Categorical**: Fill missing with column modes.

5. **Aggregate Features**

   * Group by `Season` & `DriverCode` to one row per driver-season.
   * **Numeric**: Mean or sum for continuous metrics.
   * **Mode**: Most common `Constructor` and `Tire Compound`.
   * **Label**: Max of `IsChampion`.

6. **Exploratory Visualizations**

   * Correlation matrix of numeric features.
   * Top 10 feature importances from a Random Forest.

7. **Feature Selection & Importances**

   * Apply `SelectKBest` (ANOVA F-test) to score all features.
   * Plot the highest-scoring features.

8. **Prepare ML Dataset**

   * Create `ChampionNext` by shifting `IsChampion` to the next season.
   * Split into training (≤2022) and testing (2023) sets.
   * Drop identifier columns (`Season`, `DriverCode`).

9. **Model Training & Evaluation**

   * Balance classes with `RandomOverSampler`.
   * Train the following models:

     * Logistic Regression
     * Random Forest (max\_depth=5)
     * Gaussian Naive Bayes
     * K-Nearest Neighbors (k=5)
   * Evaluate on 2023 data:

     * Accuracy
     * Weighted F1 score
     * Classification report
     * Confusion matrix

   | Model               | Accuracy | F1 Score |
   | ------------------- | -------- | -------- |
   | Logistic Regression | 0.XXX    | 0.XXX    |
   | Random Forest       | 0.XXX    | 0.XXX    |
   | Naive Bayes         | 0.XXX    | 0.XXX    |
   | K-Nearest Neighbors | 0.XXX    | 0.XXX    |

10. **Final Model & 2025 Prediction**

    * Retrain the best model on all data up to 2023.
    * Predict championship probabilities for each driver in the 2024 season.
    * Output the top-5 drivers by probability.

## License

MIT License © 2025
